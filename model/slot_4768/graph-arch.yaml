class_name: Model
config:
  input_layers:
  - [words_input, 0, 0]
  layers:
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [null, 67]
      input_dtype: int32
      name: words_input
    inbound_nodes: []
    name: words_input
  - class_name: Embedding
    config:
      W_constraint: null
      W_regularizer: null
      activity_regularizer: null
      batch_input_shape: !!python/tuple [null, 67]
      dropout: 0.0
      init: uniform
      input_dim: 2254
      input_dtype: int32
      input_length: 67
      mask_zero: true
      name: embedding_1
      output_dim: 512
      trainable: true
    inbound_nodes:
    - - [words_input, 0, 0]
    name: embedding_1
  - class_name: Dropout
    config: {name: dropout_1, p: 0.5, trainable: true}
    inbound_nodes:
    - - [embedding_1, 0, 0]
    name: dropout_1
  - class_name: LSTM
    config: {U_regularizer: null, W_regularizer: null, activation: tanh, b_regularizer: null,
      consume_less: cpu, dropout_U: 0.0, dropout_W: 0.0, forget_bias_init: one, go_backwards: false,
      init: glorot_uniform, inner_activation: hard_sigmoid, inner_init: orthogonal,
      input_dim: 512, input_length: null, name: LSTM_forward, output_dim: 128, return_sequences: true,
      stateful: false, trainable: true, unroll: false}
    inbound_nodes:
    - - [dropout_1, 0, 0]
    name: LSTM_forward
  - class_name: LSTM
    config: {U_regularizer: null, W_regularizer: null, activation: tanh, b_regularizer: null,
      consume_less: cpu, dropout_U: 0.0, dropout_W: 0.0, forget_bias_init: one, go_backwards: true,
      init: glorot_uniform, inner_activation: hard_sigmoid, inner_init: orthogonal,
      input_dim: 512, input_length: null, name: LSTM_backward, output_dim: 128, return_sequences: true,
      stateful: false, trainable: true, unroll: false}
    inbound_nodes:
    - - [dropout_1, 0, 0]
    name: LSTM_backward
  - class_name: Dropout
    config: {name: dropout_2, p: 0.5, trainable: true}
    inbound_nodes:
    - - [LSTM_forward, 0, 0]
    name: dropout_2
  - class_name: Dropout
    config: {name: dropout_3, p: 0.5, trainable: true}
    inbound_nodes:
    - - [LSTM_backward, 0, 0]
    name: dropout_3
  - class_name: Merge
    config: {concat_axis: -1, dot_axes: -1, mode: concat, mode_type: raw, name: merge_bidirections,
      output_shape: null, output_shape_type: raw}
    inbound_nodes:
    - - [dropout_2, 0, 0]
      - [dropout_3, 0, 0]
    name: merge_bidirections
  - class_name: LSTM
    config: {U_regularizer: null, W_regularizer: null, activation: tanh, b_regularizer: null,
      consume_less: cpu, dropout_U: 0.0, dropout_W: 0.0, forget_bias_init: one, go_backwards: false,
      init: glorot_uniform, inner_activation: hard_sigmoid, inner_init: orthogonal,
      input_dim: 256, input_length: null, name: summarize_to_dense, output_dim: 128,
      return_sequences: false, stateful: false, trainable: true, unroll: false}
    inbound_nodes:
    - - [merge_bidirections, 0, 0]
    name: summarize_to_dense
  - class_name: Dropout
    config: {name: dropout_4, p: 0.5, trainable: true}
    inbound_nodes:
    - - [summarize_to_dense, 0, 0]
    name: dropout_4
  - class_name: TimeDistributed
    config:
      layer:
        class_name: Dense
        config: {W_constraint: null, W_regularizer: null, activation: softmax, activity_regularizer: null,
          b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform,
          input_dim: null, name: dense_1, output_dim: 88, trainable: true}
      name: slot_output
      trainable: true
    inbound_nodes:
    - - [merge_bidirections, 0, 0]
    name: slot_output
  - class_name: Dense
    config: {W_constraint: null, W_regularizer: null, activation: sigmoid, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, init: glorot_uniform, input_dim: null,
      name: intent_output, output_dim: 69, trainable: true}
    inbound_nodes:
    - - [dropout_4, 0, 0]
    name: intent_output
  name: model_1
  output_layers:
  - [slot_output, 0, 0]
  - [intent_output, 0, 0]
keras_version: 1.0.8
